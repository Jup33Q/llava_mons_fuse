# llava_mons_fuse

this is my attempt of using llava architecture provided by huggingface
## LlaVA/LlaVA_Next Architecture
details see
```
streamlit run main.py
```
### Abstract

this document is about using native transfromers funtionals to apply llava architecture 
(with CLIPS by openai) on ready llms like llama and qwen (here we use qwen2.5:7b as an example).

\n as a hint, see huggingface docs for detials on llava and llava_next config functionals (links as bellow):
\nllava:
\nhttps://huggingface.co/docs/transformers/main/en/model_doc/llava#transformers.LlavaConfig
\nllava_next:
\nhttps://huggingface.co/docs/transformers/main/en/model_doc/llava_next#transformers.LlavaNextConfig

